{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Team members](#team)\n",
    "2. [Libraries](#libraries)\n",
    "3. [Exploring data](#exploring)\n",
    "4. [Preprocessing data](#preprocessing)\n",
    "5. [Questions](#questions)\n",
    "    - [Question 1](#question-1)\n",
    "    - [Question 2](#question-2)\n",
    "    - [Question 3](#question-3)\n",
    "    - [Question 4](#question-4)\n",
    "    - [Question 5](#question-5)\n",
    "6. [Modelling](#modelling)\n",
    "    - [Data preparation](#modelling_preparation)\n",
    "    - [Models: ](#models)\n",
    "        - [Model 1 (change the number to the name of model. Ex: 1 -> Logistic Regression)](#model1)\n",
    "    - [Evaluation](#evaluation)\n",
    "7. [Reflection](#reflection)\n",
    "    - [Difficulties during the project](#difficulties)\n",
    "    - [Useful things learned](#useful)\n",
    "    - [Plans to improve if have more time](#plans)\n",
    "8. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"team\">1. Team members</h1>\n",
    "<style>\n",
    "  table {\n",
    "    margin: auto;\n",
    "    width: 45%; /* Adjust the width as needed */\n",
    "  }\n",
    "  td {\n",
    "    text-align: center;\n",
    "    padding: 8px; /* Adding padding for better readability */\n",
    "  }\n",
    "  th\n",
    "  {\n",
    "    text-align: center;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th> ID </th>\n",
    "        <th> NAME </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>22127148</td>\n",
    "        <td>Dương Nhật Huy</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>22127224</td>\n",
    "        <td>Trương Thuận Kiệt</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>22127257</td>\n",
    "        <td>Phạm Minh Mẫn</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>22127492</td>\n",
    "        <td>Hồ Đăng Phúc</td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"libraries\"> 2. Libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"exploring\"> 3. Exploring data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data  = pd.read_csv('./Data/full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = raw_data.shape  \n",
    "shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The meaning of each line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each line of the dataset is a record of a movie, and all records include various features of the movie like Name, Genres, Cast, Budget, Revenue, Runtime, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicates = raw_data.duplicated().sum()\n",
    "num_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew, luckily no duplicated rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The meaning of each column\n",
    "- Title: The film title.\n",
    "- CriticScore and UserScore: Percentage-based scores from critics and users, respectively.\n",
    "- Link: URLs to movie pages.\n",
    "- PlatformReleased: Indicates release platforms, such as Cinema.\n",
    "- Cast and Director: Names of the main cast members and director.\n",
    "- Genre, Rating, and Runtime: Film genre, content rating (e.g., PG, R), and runtime.\n",
    "- Studio: The studio responsible for production or distribution.\n",
    "- Release Date: Specific release date.\n",
    "- Production Budget, Domestic Gross, and Worldwide Gross: Financial details in terms of budget and revenue.\n",
    "- Metascore and Usescore: Average scores given by critics and users on Metacritic website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = raw_data.dtypes\n",
    "dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen that, all types of each colum are currently objects. Therefore, those needs re-typing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Title, Link, PlatformReleased, Studio : These are meant to be string, so there no need to convert it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ CriticScore and UserScore are numbers, therfore we convert them into numerical datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : All numerical value are kept in float not interger because numpy require float to store nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove '%' notation and keep the score\n",
    "def get_score_percentage(score_str):\n",
    "    if pd.isna(score_str) or score_str == 'nan' or score_str == 'NaN':\n",
    "        return np.nan\n",
    "    elif re.match(r'^\\d{1,3}%$', score_str):\n",
    "            return float(score_str[:-1])\n",
    "    return np.nan\n",
    "\n",
    "raw_data['CriticScore'] = raw_data['CriticScore'].apply(get_score_percentage)\n",
    "raw_data['UserScore'] = raw_data['UserScore'].apply(get_score_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert MetaScore and UserScore into Numerical datatype too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if a string is a valid number because there are invalid value in Metascore and Userscore\n",
    "def get_score(score_str):\n",
    "    if pd.isna(score_str) or score_str == 'nan' or score_str == 'NaN':\n",
    "        return np.nan\n",
    "    elif re.match(r'^-?\\d+(\\.\\d+)?$', score_str):\n",
    "        return float(score_str)\n",
    "    return np.nan\n",
    "    \n",
    "raw_data['Metascore'] = raw_data['Metascore'].apply(get_score)\n",
    "raw_data['Userscore'] = raw_data['Userscore'].apply(get_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Because a movie may have many Actors, many Director and different Gern, we split them and store into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split string by comma seperated\n",
    "def split_item(string):\n",
    "    if pd.isna(string) or string == 'nan' or string == 'NaN':\n",
    "        return pd.NA\n",
    "    else:\n",
    "        return string.split(', ')\n",
    "    \n",
    "raw_data['Cast'] = raw_data['Cast'].apply(split_item)\n",
    "raw_data['Genre'] = raw_data['Genre'].apply(split_item)\n",
    "raw_data['Director'] = raw_data['Director'].apply(split_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ There are 10 different ratings, so we convert them into Pandas Categorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['Rating'] = raw_data['Rating'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We convert Runtime into dictionary consists of hours and minutes for easier operating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Collect runtime information and convert it into dictionary\n",
    "def get_runtime(runtime_str):\n",
    "    if pd.isna(runtime_str) or runtime_str == 'nan' or runtime_str == 'NaN':\n",
    "        return pd.NA\n",
    "    else:\n",
    "        runtime = runtime_str.split()\n",
    "\n",
    "        if 'h' in runtime[0]:   \n",
    "            hours = int(runtime[0].split('h')[0])\n",
    "            minutes = int(runtime[1].split('m')[0])\n",
    "        else:\n",
    "            hours = 0\n",
    "            minutes = int(runtime[0].split('m')[0])\n",
    "        return {'hours' : hours, 'minutes': minutes}\n",
    "\n",
    "raw_data['Runtime'] = raw_data['Runtime'].apply(get_runtime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ We convert release date into Pandas Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {'Jan' : 1, 'Feb' : 2, 'Mar' : 3, 'Apr' : 4, 'May' : 5, 'Jun' : 6, 'Jul' : 7, 'Aug' : 8, 'Sep' : 9, 'Oct' : 10, 'Nov' : 11, 'Dec' : 12}\n",
    "\n",
    "# Collect date string and store it into datetime format\n",
    "def parse_datetime(date_str):\n",
    "    if pd.isna(date_str) or date_str == 'nan' or date_str == 'NaN' or date_str == 'Unknown':\n",
    "        return pd.NaT\n",
    "    else:\n",
    "        date = date_str.replace(',','').split()\n",
    "        if len(date) == 1:\n",
    "            year = int(date[0])\n",
    "            return pd.to_datetime(year, format ='%Y')\n",
    "        elif len(date) == 2:\n",
    "            month = month_dict[date[0]]\n",
    "            year = int(date[1])\n",
    "            day = 1\n",
    "            return pd.to_datetime(f'{year}-{month}-{day}', format='%Y-%m-%d')\n",
    "        else:\n",
    "            month = month_dict[date[0]]\n",
    "            day = int(date[1])\n",
    "            year = int(date[2])\n",
    "            return pd.to_datetime(f'{year}-{month}-{day}', format='%Y-%m-%d')\n",
    "\n",
    "raw_data['Release Date'] = raw_data['Release Date'].apply(parse_datetime)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Finally, convert Budgets and Grossess into numerical datatype and we are done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace $ notation, replace comma and get the value\n",
    "def parse_money(money_str):\n",
    "    if pd.isna(money_str) or money_str == 'nan' or money_str == 'NaN':\n",
    "        return np.nan\n",
    "    else:\n",
    "        money_str = money_str.replace('$','').replace(',','')\n",
    "        return float(money_str)\n",
    "\n",
    "raw_data['Production Budget'] = raw_data['Production Budget'].apply(parse_money)         \n",
    "raw_data['Domestic Gross'] = raw_data['Domestic Gross'].apply(parse_money)\n",
    "raw_data['Worldwide Gross'] = raw_data['Worldwide Gross'].apply(parse_money)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Rename UserScore, Userscrore columns and drop Formated name columns because we dont use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.rename(columns={'UserScore' : 'Tomatoes UserScore', 'Userscore' : 'Meta UserScore', 'CriticScore' : 'Tomatoes CriticScore', 'MetaScore': 'Meta CriticScore'}, inplace=True)\n",
    "\n",
    "raw_data = raw_data.drop('Formated name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical column exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns with numeric data types, calculate:\n",
    "- Percentage of missing values (From this and further calculation to propose a suitable approach to fill missing values of that column)\n",
    "- The min\n",
    "- The lower quartile\n",
    "- The median\n",
    "- The upper quartile\n",
    "- The max\n",
    "After calculating, give **visualization** to help get deeper understanding of data, from that graph/chart give some comments on the values' distribution of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = raw_data.select_dtypes(include=['number']).columns\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw_data['Metascore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_stats(col : pd.core.series.Series):\n",
    "    ''' \n",
    "    Function to calculate descriptive statistics for a given column\n",
    "    Input:\n",
    "        col : pd.core.series.Series : A pandas series object\n",
    "    Output:\n",
    "        dict : A dictionary containing the descriptive statistics\n",
    "    \n",
    "    '''\n",
    "\n",
    "    mean = col.mean()\n",
    "    median = col.median()\n",
    "    mode = col.mode().values[0] if len(col.mode()) > 0 else None\n",
    "    quartiles = col.quantile([0.25, 0.5, 0.75]).values\n",
    "    percentiles = col.quantile([0.1, 0.9]).values\n",
    "    deciles = col.quantile([i/10 for i in range(1, 10)]).values\n",
    "    min_val = col.min()\n",
    "    max_val = col.max()\n",
    "\n",
    "    return {'mean': mean, 'median': median, 'mode': mode, 'quartiles': quartiles, 'percentiles': percentiles, 'deciles': deciles, 'min': min_val, 'max': max_val}\n",
    "\n",
    "\n",
    "def histogram_plot(data = [], title = '', xlabel = '', ylabel = '', color = '', mean_line = False, median_line = False, bins = range(0, 100, 20)):\n",
    "    ''' \n",
    "    Function to plot a histogram of a given dataset\n",
    "    Input:\n",
    "        data : list : A list of numerical values\n",
    "        title : str : Title of the plot\n",
    "        xlabel : str : Label for the x-axis\n",
    "        ylabel : str : Label for the y-axis\n",
    "        color : str : Color of the histogram\n",
    "        mean_line : bool : Whether to plot a line for the mean\n",
    "        median_line : bool : Whether to plot a line for the median\n",
    "        bins : list : List of bin edges for the histogram\n",
    "    '''\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.histplot(data, bins=bins, color=color)\n",
    "    plt.xticks(bins)\n",
    "\n",
    "    if mean_line:\n",
    "        mean_val = data.mean()\n",
    "        plt.axvline(mean_val, color='blue', linestyle='-', linewidth=1.5, label=f\"Mean: {mean_val:.1f}\")\n",
    "    if median_line:\n",
    "        median_val = data.median()\n",
    "        plt.axvline(median_val, color='red', linestyle='-', linewidth=1.5, label=f\"Median: {median_val:.1f}\")\n",
    "\n",
    "    plt.title(title, fontweight='bold')\n",
    "    plt.xlabel(xlabel, fontweight='bold')\n",
    "    plt.ylabel(ylabel, fontweight = 'bold')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "raw_data_tmp = raw_data.copy()\n",
    "raw_data_tmp['Genre'] = raw_data_tmp['Genre'].fillna(\"\")\n",
    "genre_onehot = pd.DataFrame(mlb.fit_transform(raw_data_tmp['Genre']), columns=mlb.classes_, index=raw_data_tmp.index)\n",
    "\n",
    "rating_onehot = pd.get_dummies(raw_data_tmp['Rating'], prefix='Rating').astype(int)\n",
    "\n",
    "raw_data_tmp = pd.concat([raw_data_tmp, genre_onehot, rating_onehot], axis=1)\n",
    "raw_data_tmp = raw_data_tmp.drop(['Genre', 'Rating'], axis=1)\n",
    "\n",
    "# Conduct t-test between missing and non missing groups for target column\n",
    "def missing_ttest(target_col, data = raw_data_tmp):\n",
    "    ''' \n",
    "    Function to conduct t-test between missing and non-missing groups for each numerical column\n",
    "    Input:\n",
    "        target_col : str : The target column to check for missing values\n",
    "        data : pd.DataFrame : The dataframe containing the data\n",
    "    Output:\n",
    "        p_values_sorted : pd.DataFrame : A dataframe containing the p-values sorted in ascending order\n",
    "        proportion_significant : float : The proportion of significant features\n",
    "    '''\n",
    "\n",
    "    p_values = {}\n",
    "\n",
    "    for col in data.columns:\n",
    "        if col != target_col and np.issubdtype(data[col].dtype, np.number):\n",
    "            missing_group = data[data[target_col].isna()][col]\n",
    "            non_missing_group = data[~data[target_col].isna()][col]\n",
    "\n",
    "            if len(missing_group) > 0 and len(non_missing_group) > 0:\n",
    "                ttest_result = ttest_ind(missing_group, non_missing_group, nan_policy='omit')\n",
    "                p_values[col] = ttest_result.pvalue\n",
    "\n",
    "    # Convert p-values to dataframe and sort by p-value for easy viewing\n",
    "    p_values_df = pd.DataFrame(list(p_values.items()), columns=['Column', 'pvalue'])\n",
    "    p_values_sorted = p_values_df.sort_values(by='pvalue', ascending=False)\n",
    "\n",
    "    # Calculate proportion of significant features\n",
    "    significant_features = p_values_sorted[p_values_sorted['pvalue'] < 0.05]\n",
    "    proportion_significant = significant_features.shape[0] / p_values_sorted.shape[0]\n",
    "\n",
    "    return p_values_sorted, proportion_significant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomatoes CriticsScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values: \", raw_data['Tomatoes CriticScore'].isna().mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation among other numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct t-test between missing and non-missing groups for 'Tomatoes CriticScore'\n",
    "p_values_sorted, proportion_significant = missing_ttest(target_col='Tomatoes CriticScore')\n",
    "\n",
    "# Display results\n",
    "print(\"T-test p-values between missing and non-missing groups for 'Tomatoes CriticScore':\")\n",
    "print(p_values_sorted)\n",
    "\n",
    "print(f\"Proportion of significant features: {proportion_significant:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of p-values are < 0.05, suggesting that there is no significant difference between the groups with and without Tomatoes CriticScore and rate of p-values is 0.66, which is quite high<br>\n",
    "It is likely that the missingness of Tomatoes CriticScore is **MAR** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_score = raw_data['Tomatoes CriticScore'].min()\n",
    "max_score = raw_data['Tomatoes CriticScore'].max()\n",
    "\n",
    "# Plot histogram of 'Tomatoes CriticScore'\n",
    "histogram_plot(data = raw_data['Tomatoes CriticScore'], title = 'Tomatoes Critic Score', xlabel = 'Score', ylabel = 'Frequency', color = 'skyblue', mean_line = True, median_line = True, bins = range(int(min_score), int(max_score)+1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics of the 'Tomatoes CriticScore'\n",
    "stats = descriptive_stats(raw_data['Tomatoes CriticScore'])\n",
    "\n",
    "#Range\n",
    "data_range = [stats['min'], stats['max']]\n",
    "\n",
    "print(\"Mean: \", stats['mean'])\n",
    "print(\"Median: \", stats['median'])\n",
    "print(\"Mode: \", stats['mode'])\n",
    "print(\"Quartiles: \", stats['quartiles'])\n",
    "print(\"Percentiles: \", stats['percentiles'])\n",
    "print(\"Deciles: \", stats['deciles'])\n",
    "print(\"Range: \", data_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean (58.37):** On average, movies tend to receive a critic score around 58.37 out of 100.\n",
    "\n",
    "**Median (62):** The median being higher than the mean suggests a positive skew in the distribution, meaning there are more movies with lower scores compared to higher scores.\n",
    "\n",
    "**Mode (93):** The most frequent critic score is 93. This could be due to a few movies that received exceptionally high ratings.\n",
    "\n",
    "**Quartiles:**\n",
    "\n",
    "-   Q1 (35): 25% of the movies have a critic score of 35 or lower.\n",
    "-   Q2 (Median, 62): 50% of the movies have a critic score of 62 or lower.\n",
    "-   Q3 (83): 75% of the movies have a critic score of 83 or lower.\n",
    "    \n",
    "**Percentiles:**\n",
    "\n",
    "- P10 (17): 10% of the movies have a critic score of 17 or lower.\n",
    "- P90 (93): 90% of the movies have a critic score of 93 or lower.\n",
    "\n",
    "**Deciles:** Movies tend to receive quite equal user scores from rotten tomatoes.\n",
    "\n",
    "**Range (0-100):** This indicates that the critic scores range from 0 to 100, which is expected for a rating system.\n",
    "\n",
    "**Overall, the summary statistics suggest a distribution that is skewed towards lower scores, with a few outliers on the higher end.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomatoes UserScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values: \", raw_data['Tomatoes UserScore'].isna().mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Correlation among other numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct t-test between missing and non-missing groups for 'Tomatoes UserScore'\n",
    "p_values_sorted, proportion_significant = missing_ttest(target_col='Tomatoes UserScore')\n",
    "\n",
    "# Display results\n",
    "print(\"T-test p-values between missing and non-missing groups for 'Tomatoes UserScore':\")\n",
    "print(p_values_sorted)\n",
    "\n",
    "print(f\"Proportion of significant features: {proportion_significant:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of p-values are < 0.05, suggesting that there is no significant difference between the groups with and without Tomatoes CriticScore and rate of p-values is 0.72, which is quite high<br>\n",
    "It is likely that the missingness of Tomatoes UserScore is **MAR** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of scores\n",
    "histogram_plot(data = raw_data['Tomatoes UserScore'], title = 'Tomatoes User Score', xlabel = 'Score', ylabel = 'Frequency', color = 'skyblue', mean_line = True, median_line = True, bins = range(0, 100, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics of the 'Tomatoes UserScore'\n",
    "stats = descriptive_stats(raw_data['Tomatoes UserScore'])\n",
    "\n",
    "#Range\n",
    "data_range = [stats['min'], stats['max']]\n",
    "\n",
    "print(\"Mean: \", stats['mean'])\n",
    "print(\"Median: \", stats['median'])\n",
    "print(\"Mode: \", stats['mode'])\n",
    "print(\"Quartiles: \", stats['quartiles'])\n",
    "print(\"Percentiles: \", stats['percentiles'])\n",
    "print(\"Deciles: \", stats['deciles'])\n",
    "print(\"Range: \", data_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean (62.45):** On average, movies tend to receive a user score around 62.45 out of 100.\n",
    "\n",
    "**Median (65):** The median being higher than the mean suggests a positive skew in the distribution, meaning there are more movies with lower scores compared to higher scores.\n",
    "\n",
    "**&rarr; The mean (62.46) and median (65.0) values are relatively high, especially when considering a scoring scale that ranges from 0 to 100. This suggests that, on average, users are rating items above the midpoint (50), indicating a general tendency to rate positively**\n",
    "\n",
    "**Mode (79):** The most frequent critic score is 79. This could be due to a few movies that received exceptionally high ratings.\n",
    "\n",
    "**&rarr; A significant number of users have rated items favorably, as scores in the upper range are generally seen as positive**\n",
    "\n",
    "**Quartiles:**\n",
    "\n",
    "-   Q1 (47): 25% of the movies have a critic score of 47 or lower.\n",
    "-   Q2 (Median, 65): 50% of the movies have a critic score of 65 or lower.\n",
    "-   Q3 (80): 75% of the movies have a critic score of 89 or lower.\n",
    "    \n",
    "**&rarr; Many users are giving high ratings**\n",
    " \n",
    "**Percentiles:**\n",
    "\n",
    "- P10 (33): 10% of the movies have a critic score of 33 or lower.\n",
    "- P90 (89): 90% of the movies have a critic score of 89 or lower.\n",
    "\n",
    "**Deciles:** Movies tend to receive quite equal user score from rotten tomatoes.\n",
    "\n",
    "**Range (0-100):** This indicates that the critic scores range from 0 to 100, which is expected for a rating system.\n",
    "\n",
    "**While the presence of low scores does indicate that not all ratings are high, the overall trend in the statistics shows a clustering of scores towards the upper end. This is a common pattern seen in products or content that are generally well-received.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values: \", raw_data['Production Budget'].isna().mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line graph of production budget over time\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "raw_data.groupby('Release Date')['Production Budget'].mean().plot(title='Production Budget Over Time', ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics of the 'Production Budget'\n",
    "stats = descriptive_stats(raw_data['Production Budget'])\n",
    "\n",
    "#Range\n",
    "data_range = [stats['min'], stats['max']]\n",
    "\n",
    "print(\"Mean: \", stats['mean'])\n",
    "print(\"Median: \", stats['median'])\n",
    "print(\"Mode: \", stats['mode'])\n",
    "print(\"Quartiles: \", stats['quartiles'])\n",
    "print(\"Percentiles: \", stats['percentiles'])\n",
    "print(\"Deciles: \", stats['deciles'])\n",
    "print(\"Range: \", data_range)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean (33,937,859.53):** The average production budget is approximately 33,937,859.53. This indicates that, on average, films are funded at a substantial level, suggesting a significant investment in movie production.\n",
    "\n",
    "**Median (18,000,000.0):** The median budget being 18,000,000.0 is notably lower than the mean, indicating a positive skew in the distribution. This suggests that while there are some films with very high budgets, many productions operate with more modest funding levels.\n",
    "\n",
    "**→ The mean (33,937,859.53) and median (18,000,000.0) values suggest that while there are high-budget films, a significant number of productions are budgeted below the average, highlighting a diverse range of film financing.**\n",
    "\n",
    "**Mode (20,000,000.0):** The mode of 20,000,000.0 indicates that this is the most common budget level among films. This clustering suggests a popular threshold for many productions, potentially reflecting industry standards or target funding levels.\n",
    "\n",
    "**&rarr; A considerable number of films are being funded around this budget mark, indicating a trend in production financing.**\n",
    "\n",
    "**Quartiles:**\n",
    "\n",
    "- Q1 (5,000,000): 25% of films have budgets of 5,000,000 or lower, illustrating that a notable portion of productions are budget-conscious.\n",
    "- Q2 (Median, 18,000,000): 50% of productions have budgets of 18,000,000 or lower, reinforcing that half of the films operate with relatively lower funding.\n",
    "- Q3 (43,750,000): 75% of films have budgets below 43,750,000, suggesting that a significant number of productions are still well below the high-budget threshold.\n",
    "\n",
    "**&rarr;** The quartile data indicates a wide range of budgets across the industry, with a substantial number of films receiving moderate to high levels of funding.\n",
    "\n",
    "**Percentiles:**\n",
    "\n",
    "P10 (1,200,000): 10% of films have budgets of 1,200,000 or lower, indicating that there are some very low-budget projects in the market.\n",
    "P90 (85,000,000): 90% of films are budgeted below 85,000,000, showcasing that while high-budget films exist, the majority still fall within a lower range.\n",
    "\n",
    "**Deciles:** The decile analysis indicates a fairly even distribution of budgets, suggesting that production funding is relatively accessible across a spectrum of films.\n",
    "\n",
    "**Range (0-460,000,000):** The range of budgets from 86.0 to 460,000,000.0 confirms the presence of extreme outliers, reflecting the diversity in production financing strategies.\n",
    "\n",
    "**Overall, while the presence of low budgets indicates that not all productions are highly funded, the majority of the data reflects a tendency towards higher investment in film production. This suggests a competitive landscape where a mix of both high-budget and lower-budget films coexist, potentially allowing for varied audience engagement and market opportunities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domestic Gross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Missing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values: \", raw_data['Domestic Gross'].isna().mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Line graph of production budget over time\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "raw_data.groupby('Release Date')['Domestic Gross'].mean().plot(title='Domestic Gross Over Time', ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive statistics of the 'Domestic Gross'\n",
    "stats = descriptive_stats(raw_data['Domestic Gross'])\n",
    "\n",
    "#Range\n",
    "data_range = [stats['min'], stats['max']]\n",
    "\n",
    "print(\"Mean: \", stats['mean'])\n",
    "print(\"Median: \", stats['median'])\n",
    "print(\"Mode: \", stats['mode'])\n",
    "print(\"Quartiles: \", stats['quartiles'])\n",
    "print(\"Percentiles: \", stats['percentiles'])\n",
    "print(\"Deciles: \", stats['deciles'])\n",
    "print(\"Range: \", data_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean (43,825,054.27):** The average domestic gross is approximately 43,825,054.27. This indicates that, on average, a reasonable return of films on domestic earnings across the production budget.\n",
    "\n",
    "**Median (17,672,451.0):** The median budget being 17,672,451.0 is notably lower than the mean, indicating a positive skew in the distribution. This suggests that where a small number of films exceptionally high.\n",
    "\n",
    "**→ Mean (43,825,054.27) and median (17,672,451.0) values suggest that while a few movies perform vary well domestically, the typical domestic gross is at very modest level**\n",
    "\n",
    "**Mode (0.0):** The mode of 0.0 indicates that a number of films do not generate any domestic revenue, possibly due to limited or no domestic release.\n",
    "\n",
    "**&rarr; This indicates that while many films have strong domestic performance, a portion either fails to secure domestic earnings or is released only internationally.**\n",
    "\n",
    "**Quartiles:**\n",
    "\n",
    "- Q1 (1,431,370.5): 25% of films have domestic return of 1,431,370.5 or lower, illustrating that a quarter of productions achieve limited domestic earnings.\n",
    "- Q2 (Median, 17,672,451.0): 50% of domestic gross of 17,672,451.0 or lower, reinforcing the trend of moderate earnings for the majority.\n",
    "- Q3 (54,141,177.5): 75% of films have budgets below 54,141,177.5, suggesting that only minority of film achieves high domestic success.\n",
    "\n",
    "**&rarr;** The quartile data reflects a broad range of domestic gross figures, with most films falling below the highest-grossing tier.\n",
    "\n",
    "**Percentiles:**\n",
    "\n",
    "P10 (0.0): 10% of films can not generate domestic gross, reinforcing the mode value.\n",
    "P90 (116,729,653): 90% of films gross are lower than 85,000,000, very high earnings are rare and achieved by a select few films.\n",
    "\n",
    "**Deciles:** The decile analysis indicates a fairly consistent distribution of domestic gross, across the lower earnings tiers, with a significant increase only in the top deciles, highlighting the influence of high-grossing outliers.\n",
    "\n",
    "**Range (0.0-858,373,000.0):** Underscores the variability in domestic gross potential, with a few films grossing exceptionally high amounts while others generate none.\n",
    "\n",
    "**Overall, the descriptive statistics and the graph show a film industry where a small number of movies achieve high domestic grosses, while most perform modestly at the box office. The increase in domestic grosses over time reflects the industry's growing focus on blockbuster movies and larger theatrical releases, which tend to generate higher revenue. However, the strong skewness suggests that blockbuster successes are exceptions rather than the norm, highlighting the industry's reliance on a few high-grossing films to drive overall box office performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worldwide Gross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Missing ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of missing values in 'Worldwide Gross'\n",
    "missing = raw_data['Worldwide Gross'].isnull().sum() / len(raw_data['Worldwide Gross']) * 100\n",
    "print(\"Percentage of missing value: \", missing, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Value Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of world wide gross through year\n",
    "raw_data.groupby('Release Date')['Worldwide Gross'].mean().plot(title='Worldwide Gross Over Time', figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew, there is no missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Descriptive Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the 'Worldwide Gross'\n",
    "stats = descriptive_stats(raw_data['Worldwide Gross'])\n",
    "\n",
    "# Range\n",
    "data_range = [stats['min'], stats['max']]\n",
    "\n",
    "print(\"Mean: \", stats['mean'])\n",
    "print(\"Median: \", stats['median'])\n",
    "print(\"Mode: \", stats['mode'])\n",
    "print(\"Quartiles: \", stats['quartiles'])\n",
    "print(\"Percentiles: \", stats['percentiles'])\n",
    "print(\"Deciles: \", stats['deciles'])\n",
    "print(\"Range: \", data_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean (Average):** The mean worldwide gross is approximately $97.5 million, suggesting that, on average, movies have generated significant revenue globally.\n",
    "\n",
    "**Median:** The median worldwide gross is around $29.6 million. This show that half of the movies made less than this amount and the other half made more then this amount.\n",
    "\n",
    "**&rarr; Mean is far higher than Median indicating that there are a few extremely high-grossing movies pulling the average up.**\n",
    "\n",
    "**Mode:** The mode is $0, which likely means that some movies generated no revenue worldwide. The reason could be movies that were not released, were not successed or error in the crawled data\n",
    "\n",
    "**Quartiles:**\n",
    "+ First Quartile (Q1): About $4.3 million. This suggests that 25% of movies earned less than this amount.\n",
    "\n",
    "+ Second Quartile (Median/Q2): $29.6 million.\n",
    "\n",
    "+ Third Quartile (Q3): Around $102 million, indicating that 75% of movies made less than this amount, and only the top 25% grossed more.\n",
    "\n",
    "**Percentiles:** The 1st percentile around $63,097 and the 99th percentile around $2.6 billion. This illustrates an extensive range in earnings, with the highest-grossing movies making much more than the vast majority.\n",
    "\n",
    "**Deciles:** \n",
    "+ 10th percentile: About $63,097\n",
    "+ 50th percentile (Median): $29.6 million\n",
    "+ 90th percentile: $259.9 million\n",
    "This shows that only a small percentage of movies reach the highest levels of worldwide gross.\n",
    "\n",
    "**Range:** From $0 to $2.9 billion, indicating a substantial difference between the least and most successful movies in terms of revenue.\n",
    "\n",
    "Overall, the data indicates a highly right skewed distribution with many movies earning relatively low revenue, while a small number reach extreme success, greatly affecting the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metascore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Missing Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values: \", raw_data['Metascore'].isna().mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Correlation among other numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct t-test between missing and non-missing groups for 'Metascore'\n",
    "p_values_sorted, proportion_significant = missing_ttest(target_col='Metascore')\n",
    "\n",
    "# Display results\n",
    "print(\"T-test p-values between missing and non-missing groups for 'Metascore':\")\n",
    "print(p_values_sorted)\n",
    "\n",
    "print(f\"Proportion of significant features: {proportion_significant:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sumary**: Around 37% of features showed significant differences(p-value < 0.05) between the group with missing and non-missing Meta Score. Therefore, the data may not entirely missing at random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of 'Metascore'\n",
    "histogram_plot(data = raw_data['Metascore'], title = 'Metascore', xlabel = 'Score', ylabel = 'Frequency', color = 'skyblue', mean_line = True, median_line = True, bins = range(0, 100, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Descriptive Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the 'Metascore'\n",
    "stats = descriptive_stats(raw_data['Metascore'])\n",
    "\n",
    "# Range\n",
    "data_range = [stats['min'], stats['max']]\n",
    "\n",
    "print(\"Mean: \", stats['mean'])\n",
    "print(\"Median: \", stats['median'])\n",
    "print(\"Mode: \", stats['mode'])\n",
    "print(\"Quartiles: \", stats['quartiles'])\n",
    "print(\"Percentiles: \", stats['percentiles'])\n",
    "print(\"Deciles: \", stats['deciles'])\n",
    "print(\"Range: \", data_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean(Average):** The mean of the 'Metascore' is approximately 55.61. This indicates that the average Metascore across the dataset is around 56, with a slight tendency towards the higher end of the scale.\n",
    "\n",
    "**Median:** The median is 55, which is very close to the mean. This suggests that the distribution of Metascore values is fairly symmetric, with half of the movies having scores below 55 and half above.\n",
    "\n",
    "**Mode:** The mode is 53, which means that the most frequent Metascore value in the dataset is 53.\n",
    "\n",
    "**Since the mode is close to Mean and Median (A little lower than them both), the data is slightly right skewed**\n",
    "\n",
    "**Quartiles:**\n",
    "+ First Quartile (Q1): 42, indicating that 25% of movies have a Metascore below 42.\n",
    "+ Second Quartile (Q2, Median): 55, indicating that 50% of the movies have a score less than or equal to 55.\n",
    "+ Third Quartile (Q3): 69, meaning 75% of movies have a Metascore below 69.\n",
    "\n",
    "**Percentiles:**\n",
    "+ The 1st percentile is 31, meaning 1% of movies have a Metascore below this value.\n",
    "+ The 99th percentile is 81, showing that 99% of movies have a Metascore below this value. This highlights that while the bulk of movies cluster in the middle, there are some with significantly higher ratings.\n",
    "\n",
    "**Deciles:** The deciles give a more granular view of the distribution, with scores ranging from 31 at the 10th percentile to 81 at the 90th percentile. The scores show a gradual increase across the deciles, reflecting a fairly uniform spread of Metascore values across the movies.\n",
    "\n",
    "**Range:** The Metascore values range from 1 to 100, indicating that the scoring system spans the entire possible range, with some movies receiving extremely low scores and others near perfect ratings.\n",
    "\n",
    "**Overall, The Metascore have a good distribution suggests that most movies fall into the middle of the scale, with fewer outliers at the end**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta UserScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Missing values Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values: \", raw_data['Meta UserScore'].isna().mean()*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Missing Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct t-test between missing and non-missing groups for 'Meta UserScore'\n",
    "p_values_sorted, proportion_significant = missing_ttest(target_col='Meta UserScore')\n",
    "\n",
    "# Display results\n",
    "print(\"T-test p-values between missing and non-missing groups for 'Meta UserScore':\")\n",
    "print(p_values_sorted)\n",
    "\n",
    "print(f\"Proportion of significant features: {proportion_significant:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sumary:** Around 44% of features showed significant differences(p-value < 0.05) between the group with missing and non-missing Meta UserScore. Therefore, the Meta UserScore may not entirely missing at random. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of 'Meta UserScore'\n",
    "histogram_plot(data = raw_data['Meta UserScore'], title = 'Meta User Score', xlabel = 'Score', ylabel = 'Frequency', color = 'skyblue', mean_line = True, median_line = True, bins = range(0, 10, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Descriptive Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the 'Meta UserScore'\n",
    "stats = descriptive_stats(raw_data['Meta UserScore'])\n",
    "\n",
    "# Range\n",
    "data_range = [stats['min'], stats['max']]\n",
    "\n",
    "print(\"Mean: \", stats['mean'])\n",
    "print(\"Median: \", stats['median'])\n",
    "print(\"Mode: \", stats['mode'])\n",
    "print(\"Quartiles: \", stats['quartiles'])\n",
    "print(\"Percentiles: \", stats['percentiles'])\n",
    "print(\"Deciles: \", stats['deciles'])\n",
    "print(\"Range: \", data_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean(Average):** The mean of the 'Meta UserScore' is approximately 6.49, indicating that the average score across the dataset is just around 6.5.\n",
    "\n",
    "**Median:**The median is 6.6, which is close to the mean. This suggests that the data is fairly symmetric, with half of the movies having scores below 6.6 and half above.\n",
    "\n",
    "**Mode:**The mode is 6.8, meaning that the most frequent Meta UserScore value in the dataset is 6.8.\n",
    "\n",
    "**Given the close values of mean and median, and the mode being slightly higher, this suggests a slightly left-skewed distribution (leaning towards higher scores).**\n",
    "\n",
    "**Quartiles:**\n",
    "+ First Quartile (Q1): 5.7, indicating that 25% of movies have a Meta UserScore below 5.7.\n",
    "+ Second Quartile (Q2, Median): 6.6, meaning that 50% of the movies have a score less than or equal to 6.6.\n",
    "+ Third Quartile (Q3): 7.4, meaning that 75% of movies have a Meta UserScore below 7.4.\n",
    "\n",
    "**Percentiles:**\n",
    "+ The 1st percentile is 4.8, meaning 1% of movies have a Meta UserScore below 4.8.\n",
    "+ The 99th percentile is 8, meaning that 99% of movies have a score below this value, showing a fairly narrow distribution at the higher end of the scale.\n",
    "\n",
    "**Deciles**:\n",
    "+ The first decile is 4.8, and the ninth decile is 8, with values gradually increasing across the deciles.\n",
    "+ The data is fairly evenly spread, though most movies score between 5.5 and 7.5.\n",
    "\n",
    "**Range**: The range of Meta UserScore is from 0.8 to 10.0, meaning that while most scores cluster around the middle, there are some extreme low and high ratings.\n",
    "\n",
    "**Overall, The Meta UserScore have a fairly balanced distribution with a little skew to the left, showing that the majority of movies have mid-range scores, with some outliers at both ends.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical column exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns with non-numeric data types, you calculate:\n",
    "- Percentage of missing values (From this and further calculation to propose a suitable approach to fill missing values of that column)\n",
    "- Count no of unique values and no of element of each value (There is a column cast is quite difficult to explore, try to find a way)\n",
    "-  Give **visualization** to help get deeper understanding of data, from that graph/chart or any collected information give some comments on the values' distribution of that column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Platform Released Column<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_count = raw_data['PlatformReleased'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "platform_count.plot(kind='bar', color='#FFB38E', edgecolor='black')\n",
    "\n",
    "plt.title('PlatformReleased Distribution', fontsize=16)\n",
    "plt.xlabel('Platform Released', fontsize=12)\n",
    "plt.ylabel('Movies Count', fontsize=12)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "for index, value in enumerate(platform_count):\n",
    "    plt.text(index, value + 50, str(value), ha='center', fontsize=10, weight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values in PlatformReleased: \", (raw_data['PlatformReleased'].isnull().sum() / len(raw_data)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of different PlatformReleased: \", len(raw_data['PlatformReleased'].unique()))\n",
    "print(\"Different PlatformReleased: \", raw_data['PlatformReleased'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Platform Release Analysis**\n",
    "\n",
    "Key Findings\n",
    "\n",
    "Column Redundancy\n",
    "\n",
    "- **Uniform Value in PlatformReleased:** The \"PlatformReleased\" column contains only one unique value, **Cinema** across all entries. This shows that every movie in this dataset was exclusively released in theaters.\n",
    "- **Lack of Differentiation:** Since the dataset only includes cinema releases, this column does not contribute additional insights.\n",
    "\n",
    "---\n",
    "Insights and Recommendations\n",
    "\n",
    "- **Redundant Data:** The single-value nature of the \"PlatformReleased\" column indicates redundancy, as it does not provide any variability or segmentation within the data.\n",
    "- **Recommendation for Data Preprocessing:** To optimize the dataset, consider removing the \"PlatformReleased\" column during preprocessing. Doing so can simplify the dataset structure and improve analysis efficiency.\n",
    "\n",
    "---\n",
    "Conclusion\n",
    "\n",
    "This dataset's exclusive focus on cinema releases makes the \"PlatformReleased\" column unnecessary for analysis. Removing it can streamline the data and enhance processing efficiency without loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Cast Column<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_actors = raw_data['Cast'].explode()\n",
    "actors_count = all_actors.value_counts()\n",
    "top_actors = actors_count.nlargest(20)\n",
    "others_count = actors_count.iloc[20:].sum()\n",
    "mean_count = actors_count.mean()\n",
    "\n",
    "top_actors = pd.concat([top_actors, pd.Series({'Others': others_count})])\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "bars = plt.barh(top_actors.index, top_actors.values, color='#9DBDFF', edgecolor='black')\n",
    "\n",
    "lim = 60\n",
    "\n",
    "for bar in bars:\n",
    "    if bar.get_width() > lim:\n",
    "        plt.text(lim + 1, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{int(bar.get_width())}', va='center', color='red', fontsize=10, weight='bold')\n",
    "    else: \n",
    "        plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{int(bar.get_width())}', va='center', color='black', fontsize=10)\n",
    "        \n",
    "plt.xlim(0, lim)\n",
    "\n",
    "plt.axvline(mean_count, color='#FF6500', linestyle='--', linewidth=1.5, label=f'Mean = {mean_count:.1f}')\n",
    "\n",
    "plt.xlabel('Movies Count')\n",
    "plt.ylabel('Actor Name')\n",
    "plt.title(f'Top 20 Actors and Others Distribution (Limited values to {lim})')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5) \n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values in Cast: \", (raw_data['Cast'].isnull().sum() / len(raw_data)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of different Casts: \", len(actors_count))\n",
    "# print(\"Different Casts: \", actors_count.index.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cast Analysis** \n",
    "\n",
    "Key Findings\n",
    "\n",
    "1. Actor Film Participation Distribution:\n",
    "\n",
    "- **Top Actors' Participation:** Among the top 20 actors in the dataset, most have appeared in between 24 and 39 movies, with Samuel L. Jackson leading by participating in 47 films.\n",
    "- **Average Participation:** On average, each actor has appeared in approximately 2.1 movies. While a few well-known actors have a high number of appearances, the majority have only one or two, reflecting a broad range of talent.\n",
    "2. Data Diversity\n",
    "\n",
    "- **Uneven Distribution of Appearances:** There is a notable disparity in film participation, with a few actors appearing in many films while most appear in significantly fewer. This imbalance suggests that a select group of actors dominates the dataset in terms of appearances.\n",
    "\n",
    "3. Missing Data\n",
    "- **Missing Percentage**: The \"Cast\" column has a missing value percentage of just 0.62%, indicating that cast information is largely complete and reliable for analysis\n",
    "---\n",
    "Insights and Recommendations\n",
    "\n",
    "- **Skewed Participation:** The unequal distribution highlights a potential bias toward a small number of frequently cast actors, which may influence insights if not accounted for.\n",
    "- **Segmentation for Deeper Insights:** To better understand trends, consider analyzing actors by segments (e.g., high, medium, and low participation levels). This could reveal patterns related to career longevity, genre focus, or popularity.\n",
    "---\n",
    "Conclusion\n",
    "\n",
    "The dataset presents a valuable overview of cast diversity, with a skew toward a select group of highly active actors. Segmenting actors based on participation frequency could help uncover nuanced trends in actor roles and career trajectories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional function to analyze categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set theme\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "data = raw_data.copy()\n",
    "\n",
    "def general_column_analysis(df, column_name, split_values=True):\n",
    "    # Percentage of missing values\n",
    "    missing_percentage = df[column_name].isnull().mean() * 100\n",
    "    \n",
    "    if split_values:\n",
    "        # Handle NaN values\n",
    "        all_values = df[column_name].fillna('')\n",
    "        \n",
    "        # Split and count\n",
    "        all_values = all_values.explode()\n",
    "        # Remove empty strings\n",
    "        all_values = all_values[all_values != '']\n",
    "        \n",
    "        unique_values = all_values.value_counts()\n",
    "        unique_count = unique_values.size\n",
    "    else:\n",
    "        # Original counting method for non-split columns\n",
    "        unique_values = df[column_name].value_counts()\n",
    "        unique_count = unique_values.size\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plot_data = unique_values.head(10)\n",
    "    \n",
    "    # Create horizontal bar plot\n",
    "    plt.barh(y=range(len(plot_data)), width=plot_data.values, \n",
    "            color=sns.color_palette(\"viridis\", 10))\n",
    "    plt.yticks(range(len(plot_data)), plot_data.index)\n",
    "    \n",
    "    # Layout\n",
    "    plt.title(f\"Top 10 Most Common Values in '{column_name}'\")\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(column_name)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # top 10 genres and their counts\n",
    "    print(\"\\nTop 10 most common values:\")\n",
    "    print(unique_values.head(10).to_frame('Count'))\n",
    "\n",
    "    return {\n",
    "        \"missing_percentage\": f\"{missing_percentage.round(3)}%\",\n",
    "        \"unique_count\": unique_count,\n",
    "        \"unique_values\": unique_values\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Director Column<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "director_analysis = general_column_analysis(data, 'Director')\n",
    "director_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directors analysis\n",
    "\n",
    "Key findings\n",
    " 1. Top 10 Most Frequent Directors\n",
    "The dataset reveals that a small group of directors has a significantly higher representation. Here are the top ten directors by count:\n",
    "\n",
    "- **Steven Spielberg**: 23 entries\n",
    "- **Clint Eastwood**: 21 entries\n",
    "- **Woody Allen**: 20 entries\n",
    "- **Ridley Scott**: 17 entries\n",
    "- **Martin Scorsese**: 14 entries\n",
    "- **Spike Lee**: 13 entries\n",
    "- **Robert Rodriguez**: 12 entries\n",
    "- **Ron Howard**: 11 entries\n",
    "- **Renny Harlin**: 11 entries\n",
    "- **Steven Soderbergh**: 11 entries\n",
    "\n",
    "    These directors represent a significant portion of the dataset, suggesting either their prolific careers or a dataset emphasis on well-known or frequently analyzed directors.\n",
    "\n",
    " 2. Data Diversity\n",
    "- **Unique Count**: There are **3,013 unique directors** in the dataset, reflecting substantial diversity with many lesser-known or single-appearance directors.\n",
    "- **Distribution**: While a few directors appear frequently, the majority appear only once, as seen in examples like T. Hee, Chinami Namba, Howard Hawks, Orson Welles, and Madoka Raine.\n",
    "\n",
    " 3. Missing Data\n",
    "- **Missing Percentage**: The dataset has a minimal missing percentage of **0.685%**. This low rate indicates good data quality, with nearly all director entries present.\n",
    "\n",
    "---\n",
    "\n",
    " Insights and Recommendations\n",
    "\n",
    "- **Data Skewness**: The distribution shows that while many unique directors are represented, a few prominent figures dominate the dataset. This skewness could influence analyses of director influence or trends, as findings may skew toward more popular directors.\n",
    "- **Analysis of Underrepresented Directors**: Given the diversity of directors, further analysis could focus on examining trends among those with only one entry. This might uncover patterns in niche genres, regional cinema, or emerging directors.\n",
    "- **Considerations for Comprehensive Analysis**: If the dataset is to be used for generalizing director trends, it might be beneficial to account for the dominance of high-frequency directors, perhaps by weighting entries or segmenting by frequency categories.\n",
    "\n",
    "---\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The dataset offers a valuable resource for analyzing directors, with strong representation from both high-profile directors and lesser-known names. The minimal missing data ensures reliability, and the diversity in director representation opens possibilities for both mainstream and niche analyses. Further examination may benefit from separating high-frequency and single-entry directors to gain insights across the spectrum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Genre Column<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_analysis = general_column_analysis(data, 'Genre')\n",
    "genre_analysis   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genre Analysis\n",
    " \n",
    " Key Findings\n",
    "1. Top 10 Most Frequent Genres\n",
    "The dataset shows a strong concentration in a few popular genres. Here are the top ten genres by frequency:\n",
    "\n",
    "- **Drama**: 2,107 entries\n",
    "- **Comedy**: 1,704 entries\n",
    "- **Mystery & Thriller**: 968 entries\n",
    "- **Action**: 890 entries\n",
    "- **Adventure**: 759 entries\n",
    "- **Horror**: 502 entries\n",
    "- **Romance**: 457 entries\n",
    "- **Fantasy**: 434 entries\n",
    "- **Kids & Family**: 408 entries\n",
    "- **Sci-Fi**: 395 entries\n",
    "\n",
    "    These top genres make up a significant portion of the dataset, highlighting an emphasis on mainstream genres that appeal broadly to audiences.\n",
    "\n",
    " 2. Data Diversity\n",
    "- **Unique Count**: The dataset includes **26 unique genres**, suggesting a moderate level of diversity.\n",
    "- **Distribution**: While certain genres are highly prevalent, others, such as *Foreign*, *Sports*, and *Faith & Spirituality*, have minimal representation (1 entry each). This distribution indicates that niche genres are underrepresented compared to popular categories like Drama and Comedy.\n",
    "\n",
    " 3. Missing Data\n",
    "- **Missing Percentage**: The dataset has a low missing percentage of **0.901%**, indicating that the genre data is largely complete and reliable.\n",
    "\n",
    "---\n",
    "\n",
    " Insights and Recommendations\n",
    "\n",
    "- **Data Skewness**: The dataset is skewed towards mainstream genres like Drama and Comedy, which could influence analyses on genre popularity or trends, favoring these popular genres over niche ones.\n",
    "- **Analysis of Underrepresented Genres**: Niche genres with few entries, such as *Foreign* and *Sports*, might benefit from separate analysis. Examining these genres could uncover unique trends and appeal factors within less common categories.\n",
    "- **Considerations for Generalization**: If the dataset is used for broad genre analysis, it's essential to account for the imbalance by potentially weighting genres or segmenting analyses to prevent dominant genres from overshadowing niche insights.\n",
    "\n",
    "---\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The dataset provides a valuable resource for genre analysis, with solid representation of mainstream genres and a lower presence of niche categories. The low missing data ensures data reliability, and the range of genres offers potential for both mainstream and niche analyses. For a comprehensive view, further segmentation by genre frequency could yield deeper insights into both widely enjoyed and specialized genres.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Rating Column<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_analysis = general_column_analysis(data, 'Rating', split_values=False)\n",
    "rating_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Analysis\n",
    "\n",
    "Key Findings\n",
    "\n",
    "1. Top 10 Most Frequent Ratings\n",
    "The dataset shows a strong concentration of content rated for mature audiences. Here are the most frequent ratings by count:\n",
    "\n",
    "- **R**: 1,886 entries\n",
    "- **PG-13**: 1,282 entries\n",
    "- **PG**: 680 entries\n",
    "- **G**: 111 entries\n",
    "- **TV-PG**: 19 entries\n",
    "- **TV-14**: 14 entries\n",
    "- **TV-MA**: 9 entries\n",
    "- **TV-G**: 7 entries\n",
    "- **NC-17**: 7 entries\n",
    "\n",
    "    The predominance of *R* and *PG-13* ratings suggests the dataset leans towards content designed for older audiences.\n",
    "\n",
    "2. Data Diversity\n",
    "- **Unique Count**: There are **9 unique ratings** within the dataset, which covers a range of audience suitability from *G* to *NC-17*.\n",
    "- **Distribution**: The bulk of entries are rated *R* and *PG-13*, while *TV* ratings (*TV-PG*, *TV-14*, *TV-MA*, *TV-G*) and *NC-17* are less represented. This distribution suggests an emphasis on theatrical releases or mature-themed content over family or TV-oriented programming.\n",
    "\n",
    "3. Missing Data\n",
    "- **Missing Percentage**: The dataset has a relatively high missing percentage of **21.367%** for ratings. This indicates that over a fifth of the entries lack rating information, potentially limiting the reliability of analyses focused on content suitability or audience targeting.\n",
    "\n",
    "---\n",
    "\n",
    "Insights and Recommendations\n",
    "\n",
    "- **Data Skewness**: With *R* and *PG-13* accounting for the majority of entries, the dataset may not reflect a balanced view of family-friendly or universally suitable content.\n",
    "- **Analysis of TV and Restricted Ratings**: The dataset includes a small portion of *TV* ratings (e.g., *TV-PG*, *TV-14*, *TV-MA*), suggesting limited representation of TV-exclusive content. If these ratings are of interest, supplementing the dataset with additional entries could provide a fuller picture of TV programming trends.\n",
    "- **Addressing Missing Ratings**: The high missing percentage may impact analyses on content rating trends. To enhance accuracy, it is recommended to either impute missing ratings where possible or treat missing data separately to avoid skewed insights.\n",
    "\n",
    "---\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The dataset provides insights primarily into mature-rated and theatrically released content, with limited representation of family-friendly or TV-specific programming. The high missing data percentage suggests caution when interpreting rating distributions, as the absence of information may impact certain analyses. To create a more balanced dataset, additional entries in family and TV categories could be considered, alongside methods to address the missing ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Studio Column<h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Distribution of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_studios = raw_data['Studio'].value_counts().nlargest(10)\n",
    "others_count = raw_data['Studio'].value_counts().iloc[10:].sum()\n",
    "top_studios = pd.concat([top_studios, pd.Series({'Others': others_count})])\n",
    "mean_count = raw_data['Studio'].value_counts().mean()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.barh(top_studios.index, top_studios.values, color='#9DBDFF', edgecolor='black')\n",
    "\n",
    "lim = 500\n",
    "\n",
    "for bar in bars:\n",
    "    if bar.get_width() > lim:\n",
    "        plt.text(lim + 5, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{int(bar.get_width())}', va='center', color='red', fontsize=10, weight='bold')\n",
    "    else:\n",
    "        plt.text(bar.get_width() + 10, bar.get_y() + bar.get_height()/2, \n",
    "                 f'{int(bar.get_width())}', va='center', color='black', fontsize=10)\n",
    "        \n",
    "plt.xlim(0, lim)\n",
    "\n",
    "plt.axvline(mean_count, color='#FF6500', linestyle='--', linewidth=1.5, label=f'Mean = {mean_count:.1f}')\n",
    "\n",
    "plt.xlabel('Movies Count')\n",
    "plt.ylabel('Studio Name')\n",
    "plt.title(f'Top 10 Studios and Others Distribution (Limited values to {lim})')\n",
    "plt.gca().invert_yaxis() \n",
    "plt.legend()\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.5) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of missing values in Studio: \", (raw_data['Studio'].isnull().sum() / len(raw_data)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of different Studios: \", len(raw_data['Studio'].unique()))\n",
    "print(\"Different Studios: \", raw_data['Studio'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Studio Analysis**\n",
    "\n",
    "Key Findings\n",
    "\n",
    "1. Top 10 Film-Producing Studios: \n",
    "\n",
    "- **Paramount Pictures:** 296 entries\n",
    "- **Universal Pictures:** 286 entries\n",
    "- **Warner Bros. Pictures:** 274 entries\n",
    "- **20th Century Fox:** 249 entries\n",
    "- **English:** 237 entries (likely indicating a category error or label misinterpretation)\n",
    "- **Sony Pictures Entertainment:** 155 entries\n",
    "- **Lionsgate Films:** 142 entries\n",
    "- **Columbia Pictures:** 118 entries\n",
    "- **Warner Bros.:** 103 entries\n",
    "- **Metro-Goldwyn-Mayer:** 94 entries\n",
    "2. Data Diversity\n",
    "\n",
    "- **Disparity Between Major and Minor Studios:** The difference in production volumes between the top studios and the overall average highlights a concentration of film production within a few major studios, suggesting that resources and distribution networks play a key role in the industry.\n",
    "\n",
    "3. Missing Data\n",
    "- **Missing Percentage**: The \"Studio\" column has a low missing data percentage of 0.92%, indicating that nearly all entries contain studio information. This high level of completeness supports reliable analysis based on studio-related insights.\n",
    "\n",
    "---\n",
    "Insights and Recommendations\n",
    "- Studio Film Production Distribution: Among the top 10 film-producing studios, five have produced more than 200 movies, with production counts ranging from 237 to 296. The remaining five studios have produced fewer than 155 movies each.\n",
    "\n",
    "- Average Film Production per Studio: On average, each studio in the dataset has produced about 4.4 movies. This highlights a significant dispersion in the film industry, where many smaller or independent studios produce fewer films, while larger studios account for the bulk of production.\n",
    "\n",
    "- Disparity Between Major and Minor Studios: The gap between the production numbers of the top 10 studios and the overall average illustrates the dominance of a few major studios in the industry, which produce far more films than smaller studios.\n",
    "\n",
    "- Recommendation for Further Analysis: This concentration of production in a few large studios suggests that financial resources and distribution networks play a crucial role in film production. It may be useful to further explore the impact of studio size and resources on film output, and consider adjusting for this disparity in any related analyses.\n",
    "    \n",
    "---\n",
    "Conclusion\n",
    "\n",
    "The dataset shows a strong concentration of production among top studios, with Paramount Pictures, Universal Pictures, and Warner Bros. Pictures leading. With a low percentage of missing data, the dataset is reliable for studio-based insights, though addressing any data mislabeling (like \"English\") is recommended for accuracy. Segmenting studios by production volume can further enrich insights into industry patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"preprocessing\"> 4. Preprocessing data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"questions\"> 5. Questions </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = question-1>5.1. Question 1</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = question-2>5.2. Question 2</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = question-3>5.3. Question 3</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = question-4>5.4. Question 4</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = question-5>5.5. Question 5</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"modelling\">6. Modelling</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = \"modelling_preparation\">6.1. Data preparation</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = \"models\">6.2. Models</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = \"models\">6.2. Models</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id = \"model1\">6.2.1 Model 1</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = \"evaluation\">6.3. Evaluation</h2> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"reflection\">7. Reflection</h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = \"difficulties\">7.1. Difficulties during the project</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = \"useful\">7.2. Useful things learned</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id = \"plans\">7.3. Plans to improve if have more time</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"references\">8. References</h1> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
