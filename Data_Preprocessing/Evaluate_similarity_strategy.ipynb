{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Libraries](#libraries)\n",
    "2. [Numerical columns](#numerical)\n",
    "3. [Categorical columns](#categorical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"libraries\"> 1. Libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../Data/retyped_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id = \"numerical\"> <h1>Evalutation </h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is dedicated to evaluate imputation using similarity strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Function to fill missing using similarity strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "start = 0\n",
    "end = 32\n",
    "\n",
    "# Define the function to calculate similarities\n",
    "def calculate_similarities(ratings, batch_start, batch_end):\n",
    "    # Select the batch of users\n",
    "    batch_ratings = ratings[batch_start:batch_end]\n",
    "    \n",
    "    # Calculate the absolute difference between the batch and all users\n",
    "    abs_diff = np.abs(ratings - batch_ratings.reshape(batch_end - batch_start, 1, ratings.shape[1]))\n",
    "    \n",
    "    # Calculate the mean absolute difference across movies, ignoring NaN values\n",
    "    mean_diff = np.nanmean(abs_diff, axis=2)\n",
    "    \n",
    "    # Compute similarity as the inverse of the mean absolute difference\n",
    "    similarities = 1 / (mean_diff + 0.001)  # Adding a small epsilon to avoid division by zero\n",
    "    similarities[np.isnan(similarities)] = 0\n",
    "    return similarities\n",
    "\n",
    "def fill_missing(data, batch_size = 32):\n",
    "    n_movies = data.shape[0]\n",
    "    filled_ratings = np.empty_like(data)\n",
    "    num_batches = int(np.ceil(n_movies / batch_size))\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = min((i + 1) * batch_size, n_movies)\n",
    "\n",
    "        similarities = calculate_similarities(data, start, end)\n",
    "        \n",
    "        weights = ~np.isnan(data) * similarities.reshape(end - start, -1, 1)\n",
    "        weights /= weights.sum(axis=1, keepdims=True)\n",
    "\n",
    "        filled_ratings[start:end] = np.nansum(data * weights, axis=1)\n",
    "\n",
    "    return filled_ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Evaluate by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Tomatoes CriticScore:\n",
      "Mean Absolute Error: 7.453907815631262\n",
      "Mean Squared Error: 102.86180360721441\n",
      "R² Score: 0.866499879281352\n",
      "--------\n",
      "\n",
      "Summary of Tomatoes UserScore:\n",
      "Mean Absolute Error: 10.875150300601202\n",
      "Mean Squared Error: 188.2387975951904\n",
      "R² Score: 0.548752980416857\n",
      "--------\n",
      "\n",
      "Summary of Metascore:\n",
      "Mean Absolute Error: 6.166032064128257\n",
      "Mean Squared Error: 64.38800601202405\n",
      "R² Score: 0.8176613400599261\n",
      "--------\n",
      "\n",
      "Summary of Meta UserScore:\n",
      "Mean Absolute Error: 0.5880761523046093\n",
      "Mean Squared Error: 0.6473482965931864\n",
      "R² Score: 0.580026019098285\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare the data (numeric columns only)\n",
    "columns = ['Tomatoes CriticScore', 'Tomatoes UserScore', 'Metascore', 'Meta UserScore']\n",
    "test_size = 0.3\n",
    "\n",
    "for test_col in columns:\n",
    "    # Step 1: Prepare the test dataset\n",
    "    raw_data_copy = raw_data.copy()\n",
    "    raw_data_copy.dropna(inplace=True)\n",
    "    raw_data_copy.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Select test rows (30% of the data)\n",
    "    test_rows = raw_data_copy.sample(frac=test_size, random_state=42).index\n",
    "    y_test = raw_data_copy.loc[test_rows, test_col].copy()\n",
    "\n",
    "    # Mask test column values (set them to NaN for imputation)\n",
    "    raw_data_copy.loc[test_rows, test_col] = np.nan\n",
    "\n",
    "    # Step 2: Apply KNN Imputation\n",
    "    knn_imputer = KNNImputer(n_neighbors=10, weights=\"uniform\")\n",
    "    imputed_data = knn_imputer.fit_transform(raw_data_copy[columns])\n",
    "\n",
    "    # Reconstruct the imputed DataFrame\n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=columns)\n",
    "\n",
    "    # Step 3: Evaluate the imputed values\n",
    "    y_pred = imputed_df.loc[test_rows, test_col]\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f'Summary of {test_col}:')\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('R² Score:', r2)\n",
    "    print('--------\\n')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
