{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Libraries](#libraries)\n",
    "2. [Numerical columns](#numerical)\n",
    "3. [Categorical columns](#categorical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id = \"libraries\"> 1. Libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from scipy.stats import sem\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../Data/retyped_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id = \"numerical\"> <h1> 2. Numerical columns </h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Impute missing values using KNN strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                      0\n",
       "Tomatoes CriticScore       0\n",
       "Tomatoes UserScore         0\n",
       "Link                       0\n",
       "PlatformReleased           0\n",
       "Cast                      32\n",
       "Director                  35\n",
       "Genre                     46\n",
       "Rating                  1091\n",
       "Runtime                   70\n",
       "Studio                    47\n",
       "Release Date              75\n",
       "Production Budget          0\n",
       "Domestic Gross             0\n",
       "Worldwide Gross            0\n",
       "Metascore                  0\n",
       "Meta UserScore             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data (numeric columns only)\n",
    "columns = ['Tomatoes CriticScore', 'Tomatoes UserScore', 'Metascore', 'Meta UserScore']\n",
    "\n",
    "# Copy raw data and scale 'Meta UserScore'\n",
    "data_tmp_2 = raw_data.copy()\n",
    "data_tmp_2['Meta UserScore'] = data_tmp_2['Meta UserScore'] * 10\n",
    "\n",
    "# Create an imputer\n",
    "knn_imputer = KNNImputer(n_neighbors=20, weights=\"uniform\")\n",
    "\n",
    "# Step 1: Apply KNN Imputation\n",
    "# Impute all missing values\n",
    "imputed_data = knn_imputer.fit_transform(data_tmp_2[columns])\n",
    "\n",
    "# Reconstruct the DataFrame with imputed values\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=columns)\n",
    "\n",
    "# Step 2: Fill missing values only\n",
    "for col in columns:\n",
    "    # Update only rows where the value is NaN\n",
    "    data_tmp_2[col] = data_tmp_2[col].combine_first(imputed_df[col])\n",
    "\n",
    "data_tmp_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id = \"categorical\"> <h1> 3. Categorical columns </h1> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Cast', 'Director', 'Genre', 'Rating', 'Studio', 'Release Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cast Column<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Cast: 32\n",
      "Number of missing values in Cast after Preprocess: 0\n"
     ]
    }
   ],
   "source": [
    "# First, let's look at the distribution of Cast data\n",
    "print(\"Number of missing values in Cast:\", data_tmp_2['Cast'].isnull().sum())\n",
    "\n",
    "# Create helper functions to process Cast\n",
    "def process_cast(cast_string):\n",
    "    \"\"\"Normalize Cast string\"\"\"\n",
    "    if pd.isna(cast_string):\n",
    "        return []\n",
    "    # Handle incorrect format cases\n",
    "    cast_string = str(cast_string)\n",
    "    cast_string = cast_string.replace('[', '').replace(']', '')  # Remove square brackets\n",
    "    # Split actors and remove extra whitespace\n",
    "    return [actor.strip() for actor in cast_string.split(',')]\n",
    "\n",
    "def get_similar_movies_for_cast(row, data, n_similar=5):\n",
    "    \"\"\"Find similar movies based on Director and Genre\"\"\"\n",
    "    # If both Director and Genre are missing, return random sample\n",
    "    if pd.isna(row['Director']) and pd.isna(row['Genre']):\n",
    "        return data.sample(n=n_similar)\n",
    "    \n",
    "    # Create initial mask for all rows\n",
    "    mask = pd.Series(True, index=data.index)\n",
    "    \n",
    "    # Filter by Director if available\n",
    "    if not pd.isna(row['Director']):\n",
    "        mask &= (data['Director'] == row['Director'])\n",
    "    # Filter by Genre if available  \n",
    "    if not pd.isna(row['Genre']):\n",
    "        mask &= (data['Genre'] == row['Genre'])\n",
    "    \n",
    "    # Get movies matching both filters\n",
    "    similar_movies = data[mask]\n",
    "\n",
    "    # If not enough similar movies, get more movies with same Director\n",
    "    if len(similar_movies) < n_similar and not pd.isna(row['Director']):\n",
    "        director_movies = data[data['Director'] == row['Director']]\n",
    "        # Combine and remove duplicates\n",
    "        similar_movies = pd.concat([similar_movies, director_movies]).drop_duplicates()\n",
    "    \n",
    "    # Return top n similar movies\n",
    "    return similar_movies.head(n_similar)\n",
    "\n",
    "def fill_cast(row, data):\n",
    "    \"\"\"Fill missing Cast based on similar movies\"\"\"\n",
    "    if pd.isna(row['Cast']):\n",
    "        similar_movies = get_similar_movies_for_cast(row, data)\n",
    "        # Get all casts from similar movies\n",
    "        all_casts = []\n",
    "        for _, movie in similar_movies.iterrows():\n",
    "            if not pd.isna(movie['Cast']):\n",
    "                all_casts.extend(process_cast(movie['Cast']))\n",
    "        \n",
    "        # Get the most frequent actors\n",
    "        if all_casts:\n",
    "            most_common = Counter(all_casts).most_common(3)\n",
    "            # Create string list with correct format\n",
    "            actors = [actor for actor, _ in most_common]\n",
    "            return f\"[{', '.join(f'{actor}' for actor in actors)}]\"\n",
    "        return 'Unknown Cast'\n",
    "    return row['Cast']\n",
    "\n",
    "# Save index of rows with missing Cast before filling\n",
    "missing_cast_idx = data_tmp_2[data_tmp_2['Cast'].isnull()].index\n",
    "\n",
    "# Apply missing values filling\n",
    "data_tmp_2['Cast'] = data_tmp_2.apply(lambda row: fill_cast(row, data_tmp_2), axis=1)\n",
    "\n",
    "print(\"Number of missing values in Cast after Preprocess:\", data_tmp_2['Cast'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Director Column<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Director: 35\n",
      "Number of missing values in Director after Preprocess: 0\n"
     ]
    }
   ],
   "source": [
    "# First look at the distribution of Director\n",
    "print(\"Number of missing values in Director:\", data_tmp_2['Director'].isnull().sum())\n",
    "\n",
    "def get_similar_movies_for_director(row, data, n_similar=5):\n",
    "    \"\"\"Find similar movies based on Cast and Genre\"\"\"\n",
    "    if pd.isna(row['Cast']) and pd.isna(row['Genre']):\n",
    "        return data.sample(n=n_similar)\n",
    "    \n",
    "    mask = pd.Series(True, index=data.index)\n",
    "    \n",
    "    # Use filled Cast\n",
    "    if not pd.isna(row['Cast']):\n",
    "        # Get list of actors\n",
    "        row_cast = set(process_cast(row['Cast']))\n",
    "        # Find movies with at least 1 matching actor\n",
    "        cast_mask = data['Cast'].apply(lambda x: bool(row_cast.intersection(set(process_cast(x)))))\n",
    "        mask &= cast_mask\n",
    "    \n",
    "    if not pd.isna(row['Genre']):\n",
    "        mask &= (data['Genre'] == row['Genre'])\n",
    "    \n",
    "    similar_movies = data[mask]\n",
    "    \n",
    "    # If not enough similar movies, expand by Genre\n",
    "    if len(similar_movies) < n_similar and not pd.isna(row['Genre']):\n",
    "        genre_movies = data[data['Genre'] == row['Genre']]\n",
    "        similar_movies = pd.concat([similar_movies, genre_movies]).drop_duplicates()\n",
    "    \n",
    "    return similar_movies.head(n_similar)\n",
    "\n",
    "def fill_director(row, data):\n",
    "    \"\"\"Fill missing Director based on similar movies\"\"\"\n",
    "    if pd.isna(row['Director']):\n",
    "        similar_movies = get_similar_movies_for_director(row, data)\n",
    "        # Get directors from similar movies\n",
    "        directors = []\n",
    "        for _, movie in similar_movies.iterrows():\n",
    "            if not pd.isna(movie['Director']):\n",
    "                directors.append(movie['Director'])\n",
    "        \n",
    "        # Get most frequent director\n",
    "        if directors:\n",
    "            most_common = Counter(directors).most_common(1)\n",
    "            return most_common[0][0]\n",
    "        return 'Unknown Director'\n",
    "    return row['Director']\n",
    "\n",
    "# Save indices of rows with missing Director\n",
    "missing_director_idx = data_tmp_2[data_tmp_2['Director'].isnull()].index\n",
    "\n",
    "# Apply fill_director\n",
    "data_tmp_2['Director'] = data_tmp_2.apply(lambda row: fill_director(row, data_tmp_2), axis=1)\n",
    "\n",
    "# Print number of missing values after filling\n",
    "print(\"Number of missing values in Director after Preprocess:\", data_tmp_2['Director'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Genre Column<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Genre: 46\n",
      "Number of missing values in Genre after Preprocess: 0\n"
     ]
    }
   ],
   "source": [
    "# First, let's look at the distribution of Genre data\n",
    "print(\"Number of missing values in Genre:\", data_tmp_2['Genre'].isnull().sum())\n",
    "\n",
    "# Create helper functions to process Genre\n",
    "def process_genre(genre_string):\n",
    "    \"\"\"Normalize Genre string\"\"\"\n",
    "    if pd.isna(genre_string):\n",
    "        return []\n",
    "    # Handle incorrect format cases\n",
    "    genre_string = str(genre_string)\n",
    "    genre_string = genre_string.replace('[', '').replace(']', '')  # Remove square brackets\n",
    "    # Split genres and remove extra whitespace\n",
    "    return [genre.strip() for genre in genre_string.split(',')]\n",
    "\n",
    "def get_similar_movies_for_genre(row, data, n_similar=5):\n",
    "    \"\"\"Find similar movies based on Cast and Director\"\"\"\n",
    "    if pd.isna(row['Cast']) and pd.isna(row['Director']):\n",
    "        return data.sample(n=n_similar)\n",
    "    \n",
    "    mask = pd.Series(True, index=data.index)\n",
    "    \n",
    "    # Filter by Cast if available\n",
    "    if not pd.isna(row['Cast']):\n",
    "        mask &= (data['Cast'] == row['Cast'])\n",
    "    \n",
    "    # Filter by Director if available\n",
    "    if not pd.isna(row['Director']):\n",
    "        mask &= (data['Director'] == row['Director'])\n",
    "    \n",
    "    similar_movies = data[mask]\n",
    "    \n",
    "    # If not enough similar movies, get more movies with same Director\n",
    "    if len(similar_movies) < n_similar and not pd.isna(row['Director']):\n",
    "        director_movies = data[data['Director'] == row['Director']]\n",
    "        similar_movies = pd.concat([similar_movies, director_movies]).drop_duplicates()\n",
    "    \n",
    "    return similar_movies.head(n_similar)\n",
    "\n",
    "\n",
    "def fill_genre(row, data):\n",
    "    \"\"\"Fill missing Genre based on similar movies\"\"\"\n",
    "    if pd.isna(row['Genre']):\n",
    "        similar_movies = get_similar_movies_for_genre(row, data)\n",
    "        # Get all genres from similar movies\n",
    "        all_genres = []\n",
    "        for _, movie in similar_movies.iterrows():\n",
    "            if not pd.isna(movie['Genre']):\n",
    "                all_genres.extend(process_genre(movie['Genre']))\n",
    "        \n",
    "        # Get the most frequent genres\n",
    "        if all_genres:\n",
    "            most_common = Counter(all_genres).most_common(2)  # Get 2 most common genres\n",
    "            # Create string list with correct format\n",
    "            genres = [genre for genre, _ in most_common]\n",
    "            return f\"[{', '.join(f'{genre}' for genre in genres)}]\"\n",
    "        return 'Unknown Genre'\n",
    "    return row['Genre']\n",
    "\n",
    "# Save index of rows with missing Genre before filling\n",
    "missing_genre_idx = data_tmp_2[data_tmp_2['Genre'].isnull()].index\n",
    "\n",
    "# Apply missing values filling\n",
    "data_tmp_2['Genre'] = data_tmp_2.apply(lambda row: fill_genre(row, data_tmp_2), axis=1)\n",
    "\n",
    "print(\"Number of missing values in Genre after Preprocess:\", data_tmp_2['Genre'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Rating', 'Studio', 'Release Date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Studio Column </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in Studio after Preprocess: 0\n",
      "Accuracy of the RandomForest model on the test set: 9.75%\n"
     ]
    }
   ],
   "source": [
    "# Initialize encoders for categorical columns\n",
    "encoders = {col: LabelEncoder() for col in ['Cast', 'Director', 'Genre', 'Rating', 'Studio']}\n",
    "\n",
    "# Define the similarity-based filling function\n",
    "def process_studio(studio_string):\n",
    "    \"\"\"Normalize Studio string.\"\"\" \n",
    "    if pd.isna(studio_string): \n",
    "        return 'Unknown Studio'\n",
    "    return str(studio_string).strip()\n",
    "\n",
    "def get_similar_movies_for_studio(row, data, n_similar=5):\n",
    "    \"\"\"Find similar movies based on Cast, Director, Genre, and Rating.\"\"\"\n",
    "    mask = pd.Series(True, index=data.index)\n",
    "    \n",
    "    if not pd.isna(row['Genre']):\n",
    "        mask &= (data['Genre'] == row['Genre'])\n",
    "    if not pd.isna(row['Cast']):\n",
    "        mask &= (data['Cast'] == row['Cast'])\n",
    "    if not pd.isna(row['Director']):\n",
    "        mask &= (data['Director'] == row['Director'])\n",
    "    if not pd.isna(row['Rating']):\n",
    "        mask &= (data['Rating'] == row['Rating'])\n",
    "    \n",
    "    similar_movies = data[mask]\n",
    "    if len(similar_movies) < n_similar and not pd.isna(row['Genre']):\n",
    "        genre_movies = data[data['Genre'] == row['Genre']]\n",
    "        similar_movies = pd.concat([similar_movies, genre_movies]).drop_duplicates()\n",
    "    return similar_movies.head(n_similar)\n",
    "\n",
    "def fill_studio_with_similarity(row, data):\n",
    "    \"\"\"Fill missing Studio using similarity-based method.\"\"\"\n",
    "    if pd.isna(row['Studio']):\n",
    "        similar_movies = get_similar_movies_for_studio(row, data)\n",
    "        all_studios = [process_studio(movie['Studio']) for _, movie in similar_movies.iterrows()]\n",
    "        if all_studios:\n",
    "            most_common = Counter(all_studios).most_common(1)\n",
    "            return most_common[0][0]\n",
    "    return None\n",
    "\n",
    "# Define the ML-based filling function\n",
    "def fill_studio_with_ml(row, model, encoders):\n",
    "    \"\"\"Fill missing Studio using machine learning.\"\"\"\n",
    "    if pd.isna(row['Studio']):\n",
    "        input_data = pd.DataFrame([{col: encoders[col].transform([row[col]])[0] for col in ['Cast', 'Director', 'Genre', 'Rating']}])\n",
    "        prediction = model.predict(input_data)\n",
    "        return encoders['Studio'].inverse_transform(prediction)[0]\n",
    "    return row['Studio']\n",
    "\n",
    "def hybrid_fill_studio(row, data, model, encoders):\n",
    "    \"\"\"Combine similarity-based and machine learning methods.\"\"\"\n",
    "    studio = fill_studio_with_similarity(row, data)\n",
    "    if studio is not None:\n",
    "        return studio\n",
    "    return fill_studio_with_ml(row, model, encoders)\n",
    "\n",
    "# Load data\n",
    "studio_process_data = raw_data.copy()\n",
    "\n",
    "# Prepare data for ML model\n",
    "for col in ['Cast', 'Director', 'Genre', 'Rating', 'Studio']:\n",
    "    studio_process_data[col] = studio_process_data[col].fillna('Unknown')\n",
    "    encoders[col].fit(studio_process_data[col])\n",
    "    studio_process_data[col] = encoders[col].transform(studio_process_data[col])\n",
    "\n",
    "# Split data into known and unknown Studio values\n",
    "known_studio = studio_process_data[studio_process_data['Studio'] != encoders['Studio'].transform(['Unknown'])[0]]\n",
    "X = known_studio[['Cast', 'Director', 'Genre', 'Rating']]\n",
    "y = known_studio['Studio']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier on the known data\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Apply hybrid strategy to fill missing values\n",
    "studio_process_data['Studio'] = studio_process_data.apply(\n",
    "    lambda row: hybrid_fill_studio(row, studio_process_data, rf_model, encoders), axis=1\n",
    ")\n",
    "\n",
    "# Decode Studio column back to original values\n",
    "studio_process_data['Studio'] = encoders['Studio'].inverse_transform(studio_process_data['Studio'])\n",
    "\n",
    "# Output the results\n",
    "print(\"Number of missing values in Studio after Preprocess:\", studio_process_data['Studio'].isnull().sum())\n",
    "\n",
    "# Evaluate the model's accuracy using the test set\n",
    "accuracy = accuracy_score(y_test, rf_model.predict(X_test)) * 100\n",
    "print(f\"Accuracy of the RandomForest model on the test set: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Approach for Filling Missing Studio Values (also applied on rating column)\n",
    "\n",
    "The algorithm fills missing `Studio` values in a dataset using a combination of two strategies:\n",
    "1. **Similarity-Based Approach** (using Movie attributes like Cast, Director, Genre, and Rating).\n",
    "2. **Machine Learning Model** (Random Forest Classifier) based on categorical features.\n",
    "\n",
    "### Overview\n",
    "We aim to impute missing values in the `Studio` column, which represents the production studio of a movie. The strategy involves two methods that work together:\n",
    "\n",
    "1. **Similarity-Based Method:**\n",
    "   - This approach tries to find movies that are similar to the one with the missing `Studio` value based on shared attributes (Cast, Director, Genre, and Rating).\n",
    "   - For each movie with a missing `Studio`, we find other movies in the dataset with matching attributes. The most frequent `Studio` among these similar movies is used to fill in the missing value.\n",
    "\n",
    "2. **Machine Learning Model (Random Forest):**\n",
    "   - When no suitable similar movies can be found, we fall back on using a trained machine learning model to predict the `Studio`.\n",
    "   - The model is trained on known records where the `Studio` is not missing. We use the `Cast`, `Director`, `Genre`, and `Rating` as features for predicting the `Studio` of a movie.\n",
    "\n",
    "### Step-by-Step Explanation\n",
    "\n",
    "#### 1. **Data Preprocessing and Encoding**\n",
    "   - The categorical columns (e.g., `Cast`, `Director`, `Genre`, `Rating`, and `Studio`) are encoded using **Label Encoding**. This converts the text data into numerical values so that it can be used in machine learning models.\n",
    "   - The missing values in the `Studio` column are initially marked as \"Unknown\" to handle cases where the `Studio` is missing.\n",
    "\n",
    "#### 2. **Similarity-Based Approach**\n",
    "   - For each movie with a missing `Studio`, the algorithm searches for similar movies based on shared attributes (`Cast`, `Director`, `Genre`, and `Rating`).\n",
    "   - Movies that match on multiple attributes are considered similar, and the `Studio` value of the most common similar movies is used to fill the missing `Studio`.\n",
    "\n",
    "   ##### Example:\n",
    "   - If a movie has `Cast = Actor1`, `Director = Director1`, `Genre = Action`, and `Rating = PG`, the algorithm searches for movies with the same attributes. If it finds movies with the same attributes and known `Studio`, it returns the most frequent `Studio`.\n",
    "\n",
    "#### 3. **Machine Learning Model (Random Forest)**\n",
    "   - If the similarity-based approach does not find enough similar movies (or if the `Studio` is still missing), the algorithm uses a **Random Forest Classifier** to predict the missing `Studio`.\n",
    "   - The model is trained using a dataset of movies where the `Studio` is not missing. The input features used for training are the `Cast`, `Director`, `Genre`, and `Rating`.\n",
    "   - After training, the model can predict the `Studio` for movies with missing values based on these features.\n",
    "\n",
    "   ##### Random Forest Model Training:\n",
    "   - **Features**: `Cast`, `Director`, `Genre`, `Rating`\n",
    "   - **Target**: `Studio`\n",
    "   - The model is trained on the available data, and once trained, it can be used to predict the `Studio` for rows with missing values.\n",
    "\n",
    "#### 4. **Hybrid Approach**\n",
    "   - The algorithm first attempts to fill the missing `Studio` using the similarity-based method. If the `Studio` cannot be determined through similarity, it falls back on the Random Forest model for prediction.\n",
    "   - This ensures that the algorithm works well in scenarios where similar movies exist and also uses machine learning when no direct similarity can be found.\n",
    "\n",
    "#### 5. **Final Output**\n",
    "   - The `Studio` column is fully populated with either the predicted values from the similarity-based method or the machine learning model.\n",
    "   - The dataset is then decoded back to its original categorical values for `Studio`.\n",
    "\n",
    "### Benefits of the Hybrid Approach:\n",
    "- **Accuracy**: The similarity-based method leverages domain knowledge (shared attributes between movies) to make reasonable inferences. The Random Forest model adds another layer of prediction based on historical patterns.\n",
    "- **Flexibility**: This hybrid approach can handle missing values in different scenarios, whether based on similarity or machine learning.\n",
    "- **Robustness**: By combining both methods, the algorithm is more robust to varying data distributions and can adapt to different types of missingness in the `Studio` column.\n",
    "\n",
    "### Conclusion\n",
    "This approach allows us to fill in missing `Studio` data intelligently, utilizing both rule-based similarity matching and predictive modeling, leading to more accurate and meaningful imputations for the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Rating Column </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Random Forest model: 61.2448132780083\n"
     ]
    }
   ],
   "source": [
    "# Initialize encoders for categorical columns\n",
    "encoders = {col: LabelEncoder() for col in ['Cast', 'Director', 'Genre', 'Rating', 'Studio']}\n",
    "\n",
    "# Define the similarity-based\n",
    "def process_rating(rating_value):\n",
    "    \"\"\"Normalize Rating value.\"\"\"\n",
    "    if pd.isna(rating_value):\n",
    "        return 'Unknown Rating'\n",
    "    return str(rating_value).strip()\n",
    "\n",
    "def get_similar_movies_for_rating(row, data, n_similar=5):\n",
    "    \"\"\"Find similar movies based on Cast, Director, Genre, and Studio.\"\"\"\n",
    "    mask = pd.Series(True, index=data.index)\n",
    "    \n",
    "    if not pd.isna(row['Genre']):\n",
    "        mask &= (data['Genre'] == row['Genre'])\n",
    "    if not pd.isna(row['Cast']):\n",
    "        mask &= (data['Cast'] == row['Cast'])\n",
    "    if not pd.isna(row['Director']):\n",
    "        mask &= (data['Director'] == row['Director'])\n",
    "    if not pd.isna(row['Studio']):\n",
    "        mask &= (data['Studio'] == row['Studio'])\n",
    "    \n",
    "    similar_movies = data[mask]\n",
    "    \n",
    "    if len(similar_movies) < n_similar and not pd.isna(row['Genre']):\n",
    "        genre_movies = data[data['Genre'] == row['Genre']]\n",
    "        similar_movies = pd.concat([similar_movies, genre_movies]).drop_duplicates()\n",
    "    \n",
    "    return similar_movies.head(n_similar)\n",
    "\n",
    "def fill_rating_with_similarity(row, data):\n",
    "    \"\"\"Fill missing Rating using similarity-based method.\"\"\"\n",
    "    if pd.isna(row['Rating']):\n",
    "        similar_movies = get_similar_movies_for_rating(row, data)\n",
    "        all_ratings = [process_rating(movie['Rating']) for _, movie in similar_movies.iterrows()]\n",
    "        if all_ratings:\n",
    "            most_common = Counter(all_ratings).most_common(1)\n",
    "            return most_common[0][0]\n",
    "    return None\n",
    "\n",
    "# Define the ML-based\n",
    "def fill_rating_with_ml(row, model, encoders):\n",
    "    \"\"\"Fill missing Rating using machine learning.\"\"\"\n",
    "    if pd.isna(row['Rating']):\n",
    "        input_data = pd.DataFrame([{col: encoders[col].transform([row[col]])[0] for col in ['Cast', 'Director', 'Genre', 'Studio']}])\n",
    "        prediction = model.predict(input_data)\n",
    "        return encoders['Rating'].inverse_transform(prediction)[0]\n",
    "    return row['Rating']\n",
    "\n",
    "# Combine similarity-based and ML methods (Hybrid method)\n",
    "def hybrid_fill_rating(row, data, model, encoders):\n",
    "    \"\"\"Combine similarity-based and machine learning methods for Rating.\"\"\"\n",
    "    rating = fill_rating_with_similarity(row, data)\n",
    "    if rating is not None:\n",
    "        return rating\n",
    "    return fill_rating_with_ml(row, model, encoders)\n",
    "\n",
    "rating_process_data = raw_data.copy()\n",
    "\n",
    "for col in ['Cast', 'Director', 'Genre', 'Rating', 'Studio']:\n",
    "    rating_process_data[col] = rating_process_data[col].fillna('Unknown')\n",
    "    encoders[col].fit(rating_process_data[col])\n",
    "    rating_process_data[col] = encoders[col].transform(rating_process_data[col])\n",
    "\n",
    "# Prepare training data for Random Forest model\n",
    "known_rating = rating_process_data[rating_process_data['Rating'] != encoders['Rating'].transform(['Unknown'])[0]]\n",
    "X = known_rating[['Cast', 'Director', 'Genre', 'Studio']]\n",
    "y = known_rating['Rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train Random Forest Classifier model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Apply hybrid strategy\n",
    "rating_process_data['Rating'] = rating_process_data.apply(\n",
    "    lambda row: hybrid_fill_rating(row, rating_process_data, rf_model, encoders), axis=1\n",
    ")\n",
    "\n",
    "# Decode Rating column back to original values\n",
    "rating_process_data['Rating'] = encoders['Rating'].inverse_transform(rating_process_data['Rating'])\n",
    "\n",
    "# Check results\n",
    "print(\"Accuracy score for Random Forest model:\", accuracy_score(y_test, rf_model.predict(X_test)) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Release Date Column </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.53113983548766\n"
     ]
    }
   ],
   "source": [
    "date_process_data = raw_data.copy()\n",
    "\n",
    "# Fill missing values in 'Genre' with 'Unknown'\n",
    "date_process_data['Genre'] = date_process_data['Genre'].fillna('Unknown')\n",
    "\n",
    "# extract the year from the 'Release Date'\n",
    "date_process_data['Release Year'] = pd.to_datetime(date_process_data['Release Date'], errors='coerce').dt.year\n",
    "\n",
    "# Filter out rows where Release Year is NaN)\n",
    "genre_popularity = date_process_data.dropna(subset=['Release Year']).groupby(['Genre', 'Release Year']).size().reset_index(name='Movie Count')\n",
    "\n",
    "# predict based on Genre Popularity Trend\n",
    "def predict_release_year(row, genre_popularity):\n",
    "    \"\"\"Predict the Release Year based on genre popularity trend and return date as 'yyyy-01-01'.\"\"\"\n",
    "    if pd.notna(row['Release Year']):\n",
    "        return pd.to_datetime(f\"{int(row['Release Year'])}-01-01\")\n",
    "    \n",
    "    genre = row['Genre']\n",
    "    \n",
    "    # Filter the popularity data\n",
    "    genre_trend = genre_popularity[genre_popularity['Genre'] == genre]\n",
    "    \n",
    "    # fallback\n",
    "    if genre_trend.empty:\n",
    "        # Use the median year\n",
    "        median_year = int(data['Release Year'].median())\n",
    "        return pd.to_datetime(f\"{median_year}-01-01\")\n",
    "    \n",
    "    # Sort by movie count per year and pick the year with the highest count for the genre\n",
    "    peak_year = int(genre_trend.loc[genre_trend['Movie Count'].idxmax()]['Release Year'])\n",
    "    \n",
    "    return pd.to_datetime(f\"{peak_year}-01-01\")\n",
    "\n",
    "# Apply the prediction function\n",
    "date_process_data['Predicted Release Date'] = date_process_data.apply(lambda row: predict_release_year(row, genre_popularity), axis=1)\n",
    "\n",
    "\n",
    "date_process_data['Release Date'] = pd.to_datetime(date_process_data['Release Date'], errors='coerce')\n",
    "date_process_data['Release Date'] = date_process_data['Release Date'].dt.year.apply(lambda x: pd.to_datetime(f\"{int(x)}-01-01\") if pd.notna(x) else np.nan)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(date_process_data['Release Date'], date_process_data['Predicted Release Date'])*100)\n",
    "\n",
    "# Fill missing values in 'Release Date' with 'Predicted Release Date'\n",
    "date_process_data['Release Date'] = date_process_data['Release Date'].combine_first(date_process_data['Predicted Release Date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Missing Release Year Based on Genre Popularity\n",
    "----------------------------------------------------------------------\n",
    "\n",
    "### Objective:\n",
    "\n",
    "We aim to predict missing \"Release Year\" values in a movie dataset using a genre-based popularity trend. For each missing year, we determine the most likely year based on the genre’s peak movie release count. The predicted release year is then formatted as `yyyy-01-01` (the first day of the year).\n",
    "\n",
    "### Steps to Process the Data:\n",
    "\n",
    "1.  **Load and Preprocess the Dataset**:\n",
    "    \n",
    "    *   The dataset is first loaded, and missing values in the `Genre` column are filled with a placeholder, `'Unknown'`, if applicable.\n",
    "    *   We extract the year from the `Release Date` column using `pd.to_datetime()`, which allows us to separate the date into year, month, and day.\n",
    "2.  **Genre Popularity Trend by Year**:\n",
    "    \n",
    "    *   To determine which years are most popular for each genre, we group the dataset by `Genre` and `Release Year` and count how many movies were released each year for each genre.\n",
    "    *   This count of movies per genre per year helps identify the most \"popular\" year for each genre.\n",
    "3.  **Prediction of Missing Release Year**:\n",
    "    \n",
    "    *   For each movie with a missing release year, we attempt to predict the year based on the genre’s popularity trend. If the genre has a trend for multiple years, the year with the highest movie count is chosen as the predicted year.\n",
    "    *   If a genre doesn’t have sufficient data or trends (e.g., a genre with no available release year data), we use the median year of all movies as a fallback prediction.\n",
    "4.  **Handling of Year Format**:\n",
    "    \n",
    "    *   The `Release Year` column may sometimes contain float values (e.g., `1997.0`), which can cause errors during date processing. To handle this:\n",
    "        *   We explicitly cast the `Release Year` as an integer (`int()`) to ensure the year is properly formatted.\n",
    "        *   The final predicted release date is formatted as `yyyy-01-01`, representing the first day of the predicted year. This format ensures that the data can be processed without error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values of categorical columns in the final dataset: Cast            32\n",
      "Director        35\n",
      "Genre           46\n",
      "Rating           0\n",
      "Studio           0\n",
      "Release Date     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in 'Studio' with 'Studio in Processed Data'\n",
    "raw_data['Studio'] = studio_process_data['Studio']\n",
    "# Fill missing values in 'Rating' with 'Rating in Processed Data'\n",
    "raw_data['Rating'] = rating_process_data['Rating']\n",
    "# Fill missing values in 'Release Date' with 'Predicted Release Date'\n",
    "raw_data['Release Date'] = date_process_data['Release Date']\n",
    "\n",
    "# Check if there are any missing values left\n",
    "print(\"Number of missing values of categorical columns in the final dataset:\", raw_data[['Cast', 'Director', 'Genre', 'Rating', 'Studio', 'Release Date']].isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min_ds-env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
